{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from senticnet5 import senticnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "from scipy import sparse\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('hand8_k_random.xlsx')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n"
     ]
    }
   ],
   "source": [
    "def convtodec(x):\n",
    "    val = 128\n",
    "    ret = 0\n",
    "    for y in x:\n",
    "        if(y):\n",
    "            ret+=val\n",
    "        val=val>>1\n",
    "    return ret\n",
    "labelpowerset = []\n",
    "for row in df.iterrows():\n",
    "    tmp = row[1][1:9].tolist()\n",
    "    labelpowerset.append(convtodec(tmp))\n",
    "print(len(labelpowerset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "cntpowerset = {}\n",
    "for val in labelpowerset:\n",
    "    if(val in cntpowerset):\n",
    "        cntpowerset[val]+=1\n",
    "    else:\n",
    "        cntpowerset[val]=1\n",
    "\n",
    "cntpowersetlist = []\n",
    "for key,val in cntpowerset.items():\n",
    "    cntpowersetlist.append((val,key))\n",
    "cntpowersetlist.sort(reverse=True)\n",
    "print(len(cntpowersetlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {}\n",
    "revlabel = {}\n",
    "cnt = 0\n",
    "for val in cntpowersetlist:\n",
    "    label[val[1]] = cnt\n",
    "    revlabel[cnt] = val[1]\n",
    "    cnt+=1\n",
    "powset = [label[x] for x in labelpowerset]\n",
    "df['powerset'] = powset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1870\n",
       "1      998\n",
       "2      772\n",
       "3      711\n",
       "4      348\n",
       "      ... \n",
       "85       1\n",
       "93       1\n",
       "86       1\n",
       "94       1\n",
       "91       1\n",
       "Name: powerset, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['powerset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df\n",
    "print(len(df_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_senticnet(word,em):\n",
    "    em = '#'+em.lower()\n",
    "    if(senticnet[word][4]==em or senticnet[word][5]==em):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tmp['Text']\n",
    "Y = df_tmp['powerset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17402\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df_tmp['Text'])\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(score_list,predict_score_list):\n",
    "    filter_corr = []\n",
    "    exmatch = 0\n",
    "    atleast1 = 0\n",
    "    md1 = 0\n",
    "    one_f = 0\n",
    "    more_f = 0\n",
    "    zero_f = 0\n",
    "    sm = 0\n",
    "    sdensity = 0\n",
    "    hammval = 0\n",
    "    test_len = len(predict_score_list[0])\n",
    "    for j in range(test_len):\n",
    "        cnt=0\n",
    "        for i in range(8):\n",
    "            hammval+=(score_list[i][j] ^ int(predict_score_list[i][j]))\n",
    "            if(score_list[i][j]==1):\n",
    "                cnt+=1\n",
    "                sm+=1\n",
    "        sdensity+=cnt/8\n",
    "        if(cnt==0):\n",
    "            zero_f+=1\n",
    "        if(cnt==1):\n",
    "            one_f+=1\n",
    "        if(cnt>1):\n",
    "            more_f+=1\n",
    "        for i in range(8):\n",
    "            mf = True\n",
    "            if(int(predict_score_list[i][j])!=score_list[i][j]):\n",
    "                mf=False\n",
    "                break\n",
    "        if(mf==True):\n",
    "            exmatch+=1\n",
    "            filter_corr.append(j)\n",
    "        for i in range(8):\n",
    "            if(int(predict_score_list[i][j])==score_list[i][j] and score_list[i][j]==1):\n",
    "                atleast1+=1\n",
    "                break\n",
    "        mf = False\n",
    "        for i in range(8):\n",
    "            if(int(predict_score_list[i][j])==score_list[i][j] and score_list[i][j]==1):\n",
    "                if(mf==True):\n",
    "                    md1+=1\n",
    "                    filter_corr.append(j)\n",
    "                    break\n",
    "                mf=True\n",
    "    #print(\"Label Cardinality: \"+ str(sm/test_len))\n",
    "    #print(\"Label Density: \"+ str(sdensity/test_len))\n",
    "    print(\"Hamming Loss: \"+str(hammval/(test_len*8)))\n",
    "    hamlos = hammval/(test_len*8)\n",
    "    print(\"Exact Prediction: \"+str(exmatch/test_len))\n",
    "    sub_accu = exmatch/test_len\n",
    "    #print(\"At least one label predicted: \"+str(atleast1/(test_len-zero_f)))\n",
    "    #print(\"More than one label predicted: \"+str(md1/more_f))\n",
    "    tp_sum = 0\n",
    "    fp_sum = 0\n",
    "    fn_sum = 0\n",
    "    macro_preci = 0\n",
    "    macro_recall = 0\n",
    "    macro_f1 = 0\n",
    "    for i in range(len(score_list)):\n",
    "        tmp = confusion_matrix(score_list[i],predict_score_list[i])\n",
    "        tp_sum+=tmp[0][0]\n",
    "        fp_sum+=tmp[0][1]\n",
    "        fn_sum+=tmp[1][0]\n",
    "        macro_preci_tmp=tmp[0][0]/(tmp[0][0]+tmp[0][1])\n",
    "        macro_recall_tmp=tmp[0][0]/(tmp[0][0]+tmp[1][0])\n",
    "        macro_f1 += ((2*macro_preci_tmp*macro_recall_tmp)/(macro_preci_tmp+macro_recall_tmp))\n",
    "        macro_preci+=macro_preci_tmp\n",
    "        macro_recall+=macro_recall_tmp\n",
    "        #print(macro_f1)\n",
    "    micro_preci = tp_sum/(tp_sum+fp_sum)\n",
    "    micro_recall = tp_sum/(tp_sum+fn_sum)\n",
    "    micro_f1 = (2*micro_preci*micro_recall)/(micro_preci+micro_recall)\n",
    "    macro_preci/=8\n",
    "    macro_recall/=8\n",
    "    macro_f1/=8\n",
    "    #print(micro_preci,micro_recall,micro_f1)\n",
    "    #print(macro_preci,macro_recall,macro_f1)\n",
    "    print(\"Macro F-Score: \"+str(macro_f1))\n",
    "    print(\"Micro F-Score: \"+str(micro_f1))\n",
    "    col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "    tmp = 0\n",
    "    for i in range(len(score_list)):\n",
    "        score = accuracy_score(score_list[i],predict_score_list[i]) \n",
    "        #print(col_names[i]+\" accuracy: \"+str(score))\n",
    "        tmp += score\n",
    "    print(\"Average Accuracy: \" + str(tmp/8))\n",
    "    avg_accu = tmp/8\n",
    "    return (hamlos,sub_accu,macro_f1,micro_f1,avg_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2bin(xx):\n",
    "    ret = []\n",
    "    for i in range(8):\n",
    "        if(xx & (1<<i)):\n",
    "            ret.append(1)\n",
    "        else:\n",
    "            ret.append(0)\n",
    "    #print(xx)\n",
    "    ret.reverse()\n",
    "    #print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold validation: 1\n",
      "(7650, 17402) (851, 17402)\n",
      "(7650,) (851,)\n",
      "Hamming Loss: 0.16480611045828436\n",
      "Exact Prediction: 0.2890716803760282\n",
      "Macro F-Score: 0.8694673928987255\n",
      "Micro F-Score: 0.902281832433374\n",
      "Average Accuracy: 0.8351938895417157\n",
      "\n",
      "\n",
      "k_fold validation: 2\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.175\n",
      "Exact Prediction: 0.28\n",
      "Macro F-Score: 0.8649434099652007\n",
      "Micro F-Score: 0.8961967899511514\n",
      "Average Accuracy: 0.8250000000000001\n",
      "\n",
      "\n",
      "k_fold validation: 3\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.18\n",
      "Exact Prediction: 0.2447058823529412\n",
      "Macro F-Score: 0.8597889457950241\n",
      "Micro F-Score: 0.8926315789473684\n",
      "Average Accuracy: 0.8199999999999998\n",
      "\n",
      "\n",
      "k_fold validation: 4\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17161764705882354\n",
      "Exact Prediction: 0.2858823529411765\n",
      "Macro F-Score: 0.8654152234012874\n",
      "Micro F-Score: 0.8977123323691822\n",
      "Average Accuracy: 0.8283823529411763\n",
      "\n",
      "\n",
      "k_fold validation: 5\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17352941176470588\n",
      "Exact Prediction: 0.26823529411764707\n",
      "Macro F-Score: 0.8628010118210719\n",
      "Micro F-Score: 0.897015185896317\n",
      "Average Accuracy: 0.8264705882352942\n",
      "\n",
      "\n",
      "k_fold validation: 6\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17205882352941176\n",
      "Exact Prediction: 0.2611764705882353\n",
      "Macro F-Score: 0.8664111256271365\n",
      "Micro F-Score: 0.8976557032890133\n",
      "Average Accuracy: 0.8279411764705883\n",
      "\n",
      "\n",
      "k_fold validation: 7\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17176470588235293\n",
      "Exact Prediction: 0.25058823529411767\n",
      "Macro F-Score: 0.8637620077233787\n",
      "Micro F-Score: 0.8975797965626096\n",
      "Average Accuracy: 0.8282352941176472\n",
      "\n",
      "\n",
      "k_fold validation: 8\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17279411764705882\n",
      "Exact Prediction: 0.28941176470588237\n",
      "Macro F-Score: 0.8659348772144769\n",
      "Micro F-Score: 0.897281230876825\n",
      "Average Accuracy: 0.8272058823529412\n",
      "\n",
      "\n",
      "k_fold validation: 9\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.1711764705882353\n",
      "Exact Prediction: 0.28\n",
      "Macro F-Score: 0.8655755247312311\n",
      "Micro F-Score: 0.8978768204948236\n",
      "Average Accuracy: 0.8288235294117647\n",
      "\n",
      "\n",
      "k_fold validation: 10\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.1676470588235294\n",
      "Exact Prediction: 0.28\n",
      "Macro F-Score: 0.8728854680912866\n",
      "Micro F-Score: 0.9003322259136212\n",
      "Average Accuracy: 0.8323529411764706\n",
      "\n",
      "\n",
      "Final Result: \n",
      "Average Hamming Loss: 0.1720394345752402\n",
      "Average Subset Accuracy: 0.27290716803760284\n",
      "Average Macro F-score: 0.8656984987268821\n",
      "Average Micro F-score: 0.8976563496734287\n",
      "Average of Average Accuracy: 0.8279605654247598\n"
     ]
    }
   ],
   "source": [
    "col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "hamm_score = []\n",
    "subset_accu = []\n",
    "macro_f1 = []\n",
    "micro_f1 = []\n",
    "avg_accu = []\n",
    "cnt = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    clf = RandomForestClassifier(n_estimators=300)\n",
    "    x_train,x_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = np.array(Y.iloc[train_index].tolist()),np.array(Y.iloc[test_index].tolist())\n",
    "    print(\"k_fold validation: \" + str(cnt))\n",
    "    cnt+=1\n",
    "    \n",
    "    x_train = vectorizer.transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    print(x_train.shape,x_test.shape)\n",
    "    print(y_train.shape,y_test.shape)\n",
    "    \n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score_list = []\n",
    "    predict_score_list = []\n",
    "    for i in range(len(y_test)):\n",
    "        score_list.append(convert2bin(revlabel[y_test[i]]))\n",
    "        predict_score_list.append(convert2bin(revlabel[y_pred[i]]))\n",
    "    np_score_list = np.array(score_list)\n",
    "    transpose = np_score_list.T\n",
    "    score_list = transpose.tolist()\n",
    "\n",
    "    np_predict_score_list = np.array(predict_score_list)\n",
    "    transpose = np_predict_score_list.T\n",
    "    predict_score_list = transpose.tolist()\n",
    "    \n",
    "    ret = evaluation(score_list,predict_score_list)\n",
    "    hamm_score.append(ret[0])\n",
    "    subset_accu.append(ret[1])\n",
    "    macro_f1.append(ret[2])\n",
    "    micro_f1.append(ret[3])\n",
    "    avg_accu.append(ret[4])\n",
    "    print('\\n')\n",
    "print('Final Result: ')\n",
    "print('Average Hamming Loss: '+str(sum(hamm_score)/len(hamm_score)))\n",
    "print('Average Subset Accuracy: '+str(sum(subset_accu)/len(subset_accu)))\n",
    "print('Average Macro F-score: '+str(sum(macro_f1)/len(macro_f1)))\n",
    "print('Average Micro F-score: '+str(sum(micro_f1)/len(micro_f1)))\n",
    "print('Average of Average Accuracy: '+str(sum(avg_accu)/len(avg_accu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i+1for i in range(10)]\n",
    "labels.append('average')\n",
    "hamm_score.append(sum(hamm_score)/len(hamm_score))\n",
    "subset_accu.append(sum(subset_accu)/len(subset_accu))\n",
    "macro_f1.append(sum(macro_f1)/len(macro_f1))\n",
    "micro_f1.append(sum(micro_f1)/len(micro_f1))\n",
    "avg_accu.append(sum(avg_accu)/len(avg_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-fold</th>\n",
       "      <th>Hamming loss</th>\n",
       "      <th>Subset accuracy</th>\n",
       "      <th>Macro F-score</th>\n",
       "      <th>Micro F-score</th>\n",
       "      <th>Average Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.164806</td>\n",
       "      <td>0.289072</td>\n",
       "      <td>0.869467</td>\n",
       "      <td>0.902282</td>\n",
       "      <td>0.835194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.864943</td>\n",
       "      <td>0.896197</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.244706</td>\n",
       "      <td>0.859789</td>\n",
       "      <td>0.892632</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.171618</td>\n",
       "      <td>0.285882</td>\n",
       "      <td>0.865415</td>\n",
       "      <td>0.897712</td>\n",
       "      <td>0.828382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.173529</td>\n",
       "      <td>0.268235</td>\n",
       "      <td>0.862801</td>\n",
       "      <td>0.897015</td>\n",
       "      <td>0.826471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.172059</td>\n",
       "      <td>0.261176</td>\n",
       "      <td>0.866411</td>\n",
       "      <td>0.897656</td>\n",
       "      <td>0.827941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.171765</td>\n",
       "      <td>0.250588</td>\n",
       "      <td>0.863762</td>\n",
       "      <td>0.897580</td>\n",
       "      <td>0.828235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.172794</td>\n",
       "      <td>0.289412</td>\n",
       "      <td>0.865935</td>\n",
       "      <td>0.897281</td>\n",
       "      <td>0.827206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.171176</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.865576</td>\n",
       "      <td>0.897877</td>\n",
       "      <td>0.828824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.167647</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.872885</td>\n",
       "      <td>0.900332</td>\n",
       "      <td>0.832353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average</td>\n",
       "      <td>0.172039</td>\n",
       "      <td>0.272907</td>\n",
       "      <td>0.865698</td>\n",
       "      <td>0.897656</td>\n",
       "      <td>0.827961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k-fold  Hamming loss  Subset accuracy  Macro F-score  Micro F-score  \\\n",
       "0         1      0.164806         0.289072       0.869467       0.902282   \n",
       "1         2      0.175000         0.280000       0.864943       0.896197   \n",
       "2         3      0.180000         0.244706       0.859789       0.892632   \n",
       "3         4      0.171618         0.285882       0.865415       0.897712   \n",
       "4         5      0.173529         0.268235       0.862801       0.897015   \n",
       "5         6      0.172059         0.261176       0.866411       0.897656   \n",
       "6         7      0.171765         0.250588       0.863762       0.897580   \n",
       "7         8      0.172794         0.289412       0.865935       0.897281   \n",
       "8         9      0.171176         0.280000       0.865576       0.897877   \n",
       "9        10      0.167647         0.280000       0.872885       0.900332   \n",
       "10  average      0.172039         0.272907       0.865698       0.897656   \n",
       "\n",
       "    Average Accuracy  \n",
       "0           0.835194  \n",
       "1           0.825000  \n",
       "2           0.820000  \n",
       "3           0.828382  \n",
       "4           0.826471  \n",
       "5           0.827941  \n",
       "6           0.828235  \n",
       "7           0.827206  \n",
       "8           0.828824  \n",
       "9           0.832353  \n",
       "10          0.827961  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rfc = pd.DataFrame(list(zip(labels,hamm_score,subset_accu,macro_f1,micro_f1,avg_accu)),\n",
    "              columns = ['k-fold','Hamming loss','Subset accuracy','Macro F-score','Micro F-score','Average Accuracy'])\n",
    "df_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold validation: 1\n",
      "(7650, 17402) (851, 17402)\n",
      "(7650,) (851,)\n",
      "Hamming Loss: 0.172737955346651\n",
      "Exact Prediction: 0.26556991774383076\n",
      "Macro F-Score: 0.8438113491819751\n",
      "Micro F-Score: 0.8976323119777159\n",
      "Average Accuracy: 0.8272620446533491\n",
      "\n",
      "\n",
      "k_fold validation: 2\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.18573529411764705\n",
      "Exact Prediction: 0.2611764705882353\n",
      "Macro F-Score: 0.8387801257659812\n",
      "Micro F-Score: 0.8897809581987958\n",
      "Average Accuracy: 0.8142647058823529\n",
      "\n",
      "\n",
      "k_fold validation: 3\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.1814705882352941\n",
      "Exact Prediction: 0.23058823529411765\n",
      "Macro F-Score: 0.8428557632258149\n",
      "Micro F-Score: 0.8918871561240582\n",
      "Average Accuracy: 0.8185294117647058\n",
      "\n",
      "\n",
      "k_fold validation: 4\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17911764705882352\n",
      "Exact Prediction: 0.2529411764705882\n",
      "Macro F-Score: 0.8427652931762232\n",
      "Micro F-Score: 0.8934942287513117\n",
      "Average Accuracy: 0.8208823529411765\n",
      "\n",
      "\n",
      "k_fold validation: 5\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.18191176470588236\n",
      "Exact Prediction: 0.24823529411764705\n",
      "Macro F-Score: 0.8378102347945752\n",
      "Micro F-Score: 0.8921440404568838\n",
      "Average Accuracy: 0.8180882352941177\n",
      "\n",
      "\n",
      "k_fold validation: 6\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17823529411764705\n",
      "Exact Prediction: 0.24941176470588236\n",
      "Macro F-Score: 0.8416708037550006\n",
      "Micro F-Score: 0.894222377378251\n",
      "Average Accuracy: 0.821764705882353\n",
      "\n",
      "\n",
      "k_fold validation: 7\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17779411764705882\n",
      "Exact Prediction: 0.23647058823529413\n",
      "Macro F-Score: 0.8401744975040683\n",
      "Micro F-Score: 0.89417943107221\n",
      "Average Accuracy: 0.8222058823529412\n",
      "\n",
      "\n",
      "k_fold validation: 8\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.17823529411764705\n",
      "Exact Prediction: 0.27647058823529413\n",
      "Macro F-Score: 0.8464517134832497\n",
      "Micro F-Score: 0.8943146145797002\n",
      "Average Accuracy: 0.821764705882353\n",
      "\n",
      "\n",
      "k_fold validation: 9\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.18161764705882352\n",
      "Exact Prediction: 0.2564705882352941\n",
      "Macro F-Score: 0.8393400334210848\n",
      "Micro F-Score: 0.8918469217970051\n",
      "Average Accuracy: 0.8183823529411764\n",
      "\n",
      "\n",
      "k_fold validation: 10\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651,) (850,)\n",
      "Hamming Loss: 0.1839705882352941\n",
      "Exact Prediction: 0.2564705882352941\n",
      "Macro F-Score: 0.8353268313120845\n",
      "Micro F-Score: 0.8906564111528713\n",
      "Average Accuracy: 0.8160294117647058\n",
      "\n",
      "\n",
      "Final Result: \n",
      "Average Hamming Loss: 0.18008261906407688\n",
      "Average Subset Accuracy: 0.2533805211861478\n",
      "Average Macro F-score: 0.8408986645620058\n",
      "Average Micro F-score: 0.8930158451488804\n",
      "Average of Average Accuracy: 0.8199173809359233\n"
     ]
    }
   ],
   "source": [
    "col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "hamm_score = []\n",
    "subset_accu = []\n",
    "macro_f1 = []\n",
    "micro_f1 = []\n",
    "avg_accu = []\n",
    "cnt = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    clf = SVC()\n",
    "    x_train,x_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = np.array(Y.iloc[train_index].tolist()),np.array(Y.iloc[test_index].tolist())\n",
    "    print(\"k_fold validation: \" + str(cnt))\n",
    "    cnt+=1\n",
    "    \n",
    "    x_train = vectorizer.transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    print(x_train.shape,x_test.shape)\n",
    "    print(y_train.shape,y_test.shape)\n",
    "    \n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score_list = []\n",
    "    predict_score_list = []\n",
    "    for i in range(len(y_test)):\n",
    "        score_list.append(convert2bin(revlabel[y_test[i]]))\n",
    "        predict_score_list.append(convert2bin(revlabel[y_pred[i]]))\n",
    "    np_score_list = np.array(score_list)\n",
    "    transpose = np_score_list.T\n",
    "    score_list = transpose.tolist()\n",
    "\n",
    "    np_predict_score_list = np.array(predict_score_list)\n",
    "    transpose = np_predict_score_list.T\n",
    "    predict_score_list = transpose.tolist()\n",
    "    \n",
    "    ret = evaluation(score_list,predict_score_list)\n",
    "    hamm_score.append(ret[0])\n",
    "    subset_accu.append(ret[1])\n",
    "    macro_f1.append(ret[2])\n",
    "    micro_f1.append(ret[3])\n",
    "    avg_accu.append(ret[4])\n",
    "    print('\\n')\n",
    "print('Final Result: ')\n",
    "print('Average Hamming Loss: '+str(sum(hamm_score)/len(hamm_score)))\n",
    "print('Average Subset Accuracy: '+str(sum(subset_accu)/len(subset_accu)))\n",
    "print('Average Macro F-score: '+str(sum(macro_f1)/len(macro_f1)))\n",
    "print('Average Micro F-score: '+str(sum(micro_f1)/len(micro_f1)))\n",
    "print('Average of Average Accuracy: '+str(sum(avg_accu)/len(avg_accu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i+1for i in range(10)]\n",
    "labels.append('average')\n",
    "hamm_score.append(sum(hamm_score)/len(hamm_score))\n",
    "subset_accu.append(sum(subset_accu)/len(subset_accu))\n",
    "macro_f1.append(sum(macro_f1)/len(macro_f1))\n",
    "micro_f1.append(sum(micro_f1)/len(micro_f1))\n",
    "avg_accu.append(sum(avg_accu)/len(avg_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-fold</th>\n",
       "      <th>Hamming loss</th>\n",
       "      <th>Subset accuracy</th>\n",
       "      <th>Macro F-score</th>\n",
       "      <th>Micro F-score</th>\n",
       "      <th>Average Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.172738</td>\n",
       "      <td>0.265570</td>\n",
       "      <td>0.843811</td>\n",
       "      <td>0.897632</td>\n",
       "      <td>0.827262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.185735</td>\n",
       "      <td>0.261176</td>\n",
       "      <td>0.838780</td>\n",
       "      <td>0.889781</td>\n",
       "      <td>0.814265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.181471</td>\n",
       "      <td>0.230588</td>\n",
       "      <td>0.842856</td>\n",
       "      <td>0.891887</td>\n",
       "      <td>0.818529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.179118</td>\n",
       "      <td>0.252941</td>\n",
       "      <td>0.842765</td>\n",
       "      <td>0.893494</td>\n",
       "      <td>0.820882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.181912</td>\n",
       "      <td>0.248235</td>\n",
       "      <td>0.837810</td>\n",
       "      <td>0.892144</td>\n",
       "      <td>0.818088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.178235</td>\n",
       "      <td>0.249412</td>\n",
       "      <td>0.841671</td>\n",
       "      <td>0.894222</td>\n",
       "      <td>0.821765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.177794</td>\n",
       "      <td>0.236471</td>\n",
       "      <td>0.840174</td>\n",
       "      <td>0.894179</td>\n",
       "      <td>0.822206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.178235</td>\n",
       "      <td>0.276471</td>\n",
       "      <td>0.846452</td>\n",
       "      <td>0.894315</td>\n",
       "      <td>0.821765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.181618</td>\n",
       "      <td>0.256471</td>\n",
       "      <td>0.839340</td>\n",
       "      <td>0.891847</td>\n",
       "      <td>0.818382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.183971</td>\n",
       "      <td>0.256471</td>\n",
       "      <td>0.835327</td>\n",
       "      <td>0.890656</td>\n",
       "      <td>0.816029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average</td>\n",
       "      <td>0.180083</td>\n",
       "      <td>0.253381</td>\n",
       "      <td>0.840899</td>\n",
       "      <td>0.893016</td>\n",
       "      <td>0.819917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k-fold  Hamming loss  Subset accuracy  Macro F-score  Micro F-score  \\\n",
       "0         1      0.172738         0.265570       0.843811       0.897632   \n",
       "1         2      0.185735         0.261176       0.838780       0.889781   \n",
       "2         3      0.181471         0.230588       0.842856       0.891887   \n",
       "3         4      0.179118         0.252941       0.842765       0.893494   \n",
       "4         5      0.181912         0.248235       0.837810       0.892144   \n",
       "5         6      0.178235         0.249412       0.841671       0.894222   \n",
       "6         7      0.177794         0.236471       0.840174       0.894179   \n",
       "7         8      0.178235         0.276471       0.846452       0.894315   \n",
       "8         9      0.181618         0.256471       0.839340       0.891847   \n",
       "9        10      0.183971         0.256471       0.835327       0.890656   \n",
       "10  average      0.180083         0.253381       0.840899       0.893016   \n",
       "\n",
       "    Average Accuracy  \n",
       "0           0.827262  \n",
       "1           0.814265  \n",
       "2           0.818529  \n",
       "3           0.820882  \n",
       "4           0.818088  \n",
       "5           0.821765  \n",
       "6           0.822206  \n",
       "7           0.821765  \n",
       "8           0.818382  \n",
       "9           0.816029  \n",
       "10          0.819917  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svc = pd.DataFrame(list(zip(labels,hamm_score,subset_accu,macro_f1,micro_f1,avg_accu)),\n",
    "              columns = ['k-fold','Hamming loss','Subset accuracy','Macro F-score','Micro F-score','Average Accuracy'])\n",
    "df_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
