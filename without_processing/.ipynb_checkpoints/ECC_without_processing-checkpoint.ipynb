{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from senticnet5 import senticnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "from scipy import sparse\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('hand8_k_random.xlsx')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "Y = df[['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']]\n",
    "Y = Y.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17402\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['Text'])\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6375, 17402)\n",
      "(6375, 8)\n",
      "(2126, 17402)\n"
     ]
    }
   ],
   "source": [
    "col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.25,random_state = 42)\n",
    "\n",
    "x_train = vectorizer.transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(score_list,predict_score_list):\n",
    "    filter_corr = []\n",
    "    exmatch = 0\n",
    "    atleast1 = 0\n",
    "    md1 = 0\n",
    "    one_f = 0\n",
    "    more_f = 0\n",
    "    zero_f = 0\n",
    "    sm = 0\n",
    "    sdensity = 0\n",
    "    hammval = 0\n",
    "    test_len = len(predict_score_list[0])\n",
    "    for j in range(test_len):\n",
    "        cnt=0\n",
    "        for i in range(8):\n",
    "            hammval+=(score_list[i][j] ^ int(predict_score_list[i][j]))\n",
    "            if(score_list[i][j]==1):\n",
    "                cnt+=1\n",
    "                sm+=1\n",
    "        sdensity+=cnt/8\n",
    "        if(cnt==0):\n",
    "            zero_f+=1\n",
    "        if(cnt==1):\n",
    "            one_f+=1\n",
    "        if(cnt>1):\n",
    "            more_f+=1\n",
    "        for i in range(8):\n",
    "            mf = True\n",
    "            if(int(predict_score_list[i][j])!=score_list[i][j]):\n",
    "                mf=False\n",
    "                break\n",
    "        if(mf==True):\n",
    "            exmatch+=1\n",
    "            filter_corr.append(j)\n",
    "        for i in range(8):\n",
    "            if(int(predict_score_list[i][j])==score_list[i][j] and score_list[i][j]==1):\n",
    "                atleast1+=1\n",
    "                break\n",
    "        mf = False\n",
    "        for i in range(8):\n",
    "            if(int(predict_score_list[i][j])==score_list[i][j] and score_list[i][j]==1):\n",
    "                if(mf==True):\n",
    "                    md1+=1\n",
    "                    filter_corr.append(j)\n",
    "                    break\n",
    "                mf=True\n",
    "    #print(\"Label Cardinality: \"+ str(sm/test_len))\n",
    "    #print(\"Label Density: \"+ str(sdensity/test_len))\n",
    "    print(\"Hamming Loss: \"+str(hammval/(test_len*8)))\n",
    "    print(\"Exact Prediction: \"+str(exmatch/test_len))\n",
    "    #print(\"At least one label predicted: \"+str(atleast1/(test_len-zero_f)))\n",
    "    #print(\"More than one label predicted: \"+str(md1/more_f))\n",
    "    tp_sum = 0\n",
    "    fp_sum = 0\n",
    "    fn_sum = 0\n",
    "    macro_preci = 0\n",
    "    macro_recall = 0\n",
    "    macro_f1 = 0\n",
    "    for i in range(len(score_list)):\n",
    "        tmp = confusion_matrix(score_list[i],predict_score_list[i])\n",
    "        tp_sum+=tmp[0][0]\n",
    "        fp_sum+=tmp[0][1]\n",
    "        fn_sum+=tmp[1][0]\n",
    "        macro_preci_tmp=tmp[0][0]/(tmp[0][0]+tmp[0][1])\n",
    "        macro_recall_tmp=tmp[0][0]/(tmp[0][0]+tmp[1][0])\n",
    "        macro_f1 += ((2*macro_preci_tmp*macro_recall_tmp)/(macro_preci_tmp+macro_recall_tmp))\n",
    "        macro_preci+=macro_preci_tmp\n",
    "        macro_recall+=macro_recall_tmp\n",
    "        print(macro_f1)\n",
    "    micro_preci = tp_sum/(tp_sum+fp_sum)\n",
    "    micro_recall = tp_sum/(tp_sum+fn_sum)\n",
    "    micro_f1 = (2*micro_preci*micro_recall)/(micro_preci+micro_recall)\n",
    "    macro_preci/=8\n",
    "    macro_recall/=8\n",
    "    macro_f1/=8\n",
    "    #print(micro_preci,micro_recall,micro_f1)\n",
    "    #print(macro_preci,macro_recall,macro_f1)\n",
    "    print(\"Macro F-Score: \"+str(macro_f1))\n",
    "    print(\"Micro F-Score: \"+str(micro_f1))\n",
    "    col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "    tmp = 0\n",
    "    for i in range(len(score_list)):\n",
    "        score = accuracy_score(score_list[i],predict_score_list[i]) \n",
    "        print(col_names[i]+\" accuracy: \"+str(score))\n",
    "        tmp += score\n",
    "    print(\"Average Accuracy: \" + str(tmp/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Chain 1\n",
      "Training Chain 2\n",
      "Training Chain 3\n",
      "Training Chain 4\n",
      "Training Chain 5\n",
      "Training Chain 6\n",
      "Training Chain 7\n",
      "Training Chain 8\n",
      "Training Chain 9\n",
      "Training Chain 10\n"
     ]
    }
   ],
   "source": [
    "base = RandomForestClassifier()\n",
    "\n",
    "chains = [ClassifierChain(base,order = 'random',random_state=i) for i in range(10)]\n",
    "cnt=1\n",
    "y_pred_list = []\n",
    "for chain in chains:\n",
    "    print(\"Training Chain \"+ str(cnt))\n",
    "    cnt+=1\n",
    "    chain.fit(x_train,y_train)\n",
    "    y_pred = chain.predict(x_test)\n",
    "    y_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.16521636876763876\n",
      "Exact Prediction: 0.22718720602069614\n",
      "0.8499413833528722\n",
      "1.4899813234427375\n",
      "2.433537766999181\n",
      "3.3502472785673043\n",
      "4.313932387024531\n",
      "5.274558456968283\n",
      "6.125529198012854\n",
      "7.0831646659931495\n",
      "Macro F-Score: 0.8853955832491437\n",
      "Micro F-Score: 0.9038264083783968\n",
      "Joy accuracy: 0.7591721542803387\n",
      "Sadness accuracy: 0.660865475070555\n",
      "Anger accuracy: 0.8936970837253058\n",
      "Disgust accuracy: 0.8476011288805269\n",
      "Admiration accuracy: 0.9299153339604892\n",
      "Surprise accuracy: 0.9242709313264346\n",
      "Interest accuracy: 0.7436500470366886\n",
      "Fear accuracy: 0.9190968955785512\n",
      "Average Accuracy: 0.8347836312323613\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "threshold = 5\n",
    "for i in range(len(y_pred_list[0])):\n",
    "    tmp = []\n",
    "    for j in range(len(y_pred_list[0][0])):\n",
    "        tmp.append(0)\n",
    "    y_pred.append(tmp)\n",
    "for k in range(len(y_pred_list)):\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[0])):\n",
    "            y_pred[i][j]+=y_pred_list[k][i][j]\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[0])):\n",
    "        if(y_pred[i][j]>=threshold):\n",
    "            y_pred[i][j]=1\n",
    "        else:\n",
    "            y_pred[i][j]=0\n",
    "y_pred_np = np.array(y_pred)\n",
    "score_list = y_test.T.tolist()\n",
    "predict_score_list = y_pred_np.T.tolist()\n",
    "evaluation(score_list,predict_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Chain 1\n",
      "Training Chain 2\n",
      "Training Chain 3\n",
      "Training Chain 4\n",
      "Training Chain 5\n",
      "Training Chain 6\n",
      "Training Chain 7\n",
      "Training Chain 8\n",
      "Training Chain 9\n",
      "Training Chain 10\n"
     ]
    }
   ],
   "source": [
    "base = SVC()\n",
    "\n",
    "chains = [ClassifierChain(base,order = 'random',random_state=i) for i in range(10)]\n",
    "cnt=1\n",
    "y_pred_list = []\n",
    "for chain in chains:\n",
    "    print(\"Training Chain \"+ str(cnt))\n",
    "    cnt+=1\n",
    "    chain.fit(x_train,y_train)\n",
    "    y_pred = chain.predict(x_test)\n",
    "    y_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.17421213546566322\n",
      "Exact Prediction: 0.24788334901222953\n",
      "0.8365650969529086\n",
      "1.2962476366354483\n",
      "2.2385074673970213\n",
      "3.1553234387305253\n",
      "4.119008547187752\n",
      "5.079653866180664\n",
      "5.928494324409219\n",
      "6.885935898824964\n",
      "Macro F-Score: 0.8607419873531205\n",
      "Micro F-Score: 0.8963514884388007\n",
      "Joy accuracy: 0.7502351834430856\n",
      "Sadness accuracy: 0.5997177798682972\n",
      "Anger accuracy: 0.8908748824082785\n",
      "Disgust accuracy: 0.8471307619943556\n",
      "Admiration accuracy: 0.9299153339604892\n",
      "Surprise accuracy: 0.9242709313264346\n",
      "Interest accuracy: 0.7455315145813735\n",
      "Fear accuracy: 0.91862652869238\n",
      "Average Accuracy: 0.8257878645343368\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "threshold = 5\n",
    "for i in range(len(y_pred_list[0])):\n",
    "    tmp = []\n",
    "    for j in range(len(y_pred_list[0][0])):\n",
    "        tmp.append(0)\n",
    "    y_pred.append(tmp)\n",
    "for k in range(len(y_pred_list)):\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[0])):\n",
    "            y_pred[i][j]+=y_pred_list[k][i][j]\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[0])):\n",
    "        if(y_pred[i][j]>=threshold):\n",
    "            y_pred[i][j]=1\n",
    "        else:\n",
    "            y_pred[i][j]=0\n",
    "y_pred_np = np.array(y_pred)\n",
    "score_list = y_test.T.tolist()\n",
    "predict_score_list = y_pred_np.T.tolist()\n",
    "evaluation(score_list,predict_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
