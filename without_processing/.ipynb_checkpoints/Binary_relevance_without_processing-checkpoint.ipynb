{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from senticnet5 import senticnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "from scipy import sparse\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('hand8_k_random.xlsx')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from skmultilearn.ensemble import RakelD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "X = df['Text']\n",
    "Y = df[['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17402\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['Text'])\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(score_list,predict_score_list):\n",
    "    filter_corr = []\n",
    "    exmatch = 0\n",
    "    atleast1 = 0\n",
    "    md1 = 0\n",
    "    one_f = 0\n",
    "    more_f = 0\n",
    "    zero_f = 0\n",
    "    sm = 0\n",
    "    sdensity = 0\n",
    "    hammval = 0\n",
    "    test_len = len(predict_score_list[0])\n",
    "    for j in range(test_len):\n",
    "        cnt=0\n",
    "        for i in range(8):\n",
    "            hammval+=(score_list[i][j] ^ int(predict_score_list[i][j]))\n",
    "            if(score_list[i][j]==1):\n",
    "                cnt+=1\n",
    "                sm+=1\n",
    "        sdensity+=cnt/8\n",
    "        if(cnt==0):\n",
    "            zero_f+=1\n",
    "        if(cnt==1):\n",
    "            one_f+=1\n",
    "        if(cnt>1):\n",
    "            more_f+=1\n",
    "        for i in range(8):\n",
    "            mf = True\n",
    "            if(int(predict_score_list[i][j])!=score_list[i][j]):\n",
    "                mf=False\n",
    "                break\n",
    "        if(mf==True):\n",
    "            exmatch+=1\n",
    "            filter_corr.append(j)\n",
    "        for i in range(8):\n",
    "            if(int(predict_score_list[i][j])==score_list[i][j] and score_list[i][j]==1):\n",
    "                atleast1+=1\n",
    "                break\n",
    "        mf = False\n",
    "        for i in range(8):\n",
    "            if(int(predict_score_list[i][j])==score_list[i][j] and score_list[i][j]==1):\n",
    "                if(mf==True):\n",
    "                    md1+=1\n",
    "                    filter_corr.append(j)\n",
    "                    break\n",
    "                mf=True\n",
    "    #print(\"Label Cardinality: \"+ str(sm/test_len))\n",
    "    #print(\"Label Density: \"+ str(sdensity/test_len))\n",
    "    print(\"Hamming Loss: \"+str(hammval/(test_len*8)))\n",
    "    hamlos = hammval/(test_len*8)\n",
    "    print(\"Exact Prediction: \"+str(exmatch/test_len))\n",
    "    sub_accu = exmatch/test_len\n",
    "    #print(\"At least one label predicted: \"+str(atleast1/(test_len-zero_f)))\n",
    "    #print(\"More than one label predicted: \"+str(md1/more_f))\n",
    "    tp_sum = 0\n",
    "    fp_sum = 0\n",
    "    fn_sum = 0\n",
    "    macro_preci = 0\n",
    "    macro_recall = 0\n",
    "    macro_f1 = 0\n",
    "    for i in range(len(score_list)):\n",
    "        tmp = confusion_matrix(score_list[i],predict_score_list[i])\n",
    "        tp_sum+=tmp[0][0]\n",
    "        fp_sum+=tmp[0][1]\n",
    "        fn_sum+=tmp[1][0]\n",
    "        macro_preci_tmp=tmp[0][0]/(tmp[0][0]+tmp[0][1])\n",
    "        macro_recall_tmp=tmp[0][0]/(tmp[0][0]+tmp[1][0])\n",
    "        macro_f1 += ((2*macro_preci_tmp*macro_recall_tmp)/(macro_preci_tmp+macro_recall_tmp))\n",
    "        macro_preci+=macro_preci_tmp\n",
    "        macro_recall+=macro_recall_tmp\n",
    "        #print(macro_f1)\n",
    "    micro_preci = tp_sum/(tp_sum+fp_sum)\n",
    "    micro_recall = tp_sum/(tp_sum+fn_sum)\n",
    "    micro_f1 = (2*micro_preci*micro_recall)/(micro_preci+micro_recall)\n",
    "    macro_preci/=8\n",
    "    macro_recall/=8\n",
    "    macro_f1/=8\n",
    "    #print(micro_preci,micro_recall,micro_f1)\n",
    "    #print(macro_preci,macro_recall,macro_f1)\n",
    "    print(\"Macro F-Score: \"+str(macro_f1))\n",
    "    print(\"Micro F-Score: \"+str(micro_f1))\n",
    "    col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "    tmp = 0\n",
    "    for i in range(len(score_list)):\n",
    "        score = accuracy_score(score_list[i],predict_score_list[i]) \n",
    "        #print(col_names[i]+\" accuracy: \"+str(score))\n",
    "        tmp += score\n",
    "    print(\"Average Accuracy: \" + str(tmp/8))\n",
    "    avg_accu = tmp/8\n",
    "    return (hamlos,sub_accu,macro_f1,micro_f1,avg_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold validation: 1\n",
      "(7650, 17402) (851, 17402)\n",
      "(7650, 8) (851, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.1605464159811986\n",
      "Exact Prediction: 0.19741480611045828\n",
      "Macro F-Score: 0.8942894655635346\n",
      "Micro F-Score: 0.9080508118112224\n",
      "Average Accuracy: 0.8394535840188014\n",
      "\n",
      "\n",
      "k_fold validation: 2\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16897058823529412\n",
      "Exact Prediction: 0.18470588235294116\n",
      "Macro F-Score: 0.8920388474481976\n",
      "Micro F-Score: 0.9032583985855014\n",
      "Average Accuracy: 0.8310294117647058\n",
      "\n",
      "\n",
      "k_fold validation: 3\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16779411764705882\n",
      "Exact Prediction: 0.18235294117647058\n",
      "Macro F-Score: 0.8916903666920724\n",
      "Micro F-Score: 0.9035095137420719\n",
      "Average Accuracy: 0.8322058823529412\n",
      "\n",
      "\n",
      "k_fold validation: 4\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16558823529411765\n",
      "Exact Prediction: 0.19647058823529412\n",
      "Macro F-Score: 0.8918632878309152\n",
      "Micro F-Score: 0.9049307666328943\n",
      "Average Accuracy: 0.8344117647058822\n",
      "\n",
      "\n",
      "k_fold validation: 5\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.1635294117647059\n",
      "Exact Prediction: 0.19294117647058823\n",
      "Macro F-Score: 0.8941216150206516\n",
      "Micro F-Score: 0.9064602960969044\n",
      "Average Accuracy: 0.8364705882352941\n",
      "\n",
      "\n",
      "k_fold validation: 6\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16514705882352942\n",
      "Exact Prediction: 0.18588235294117647\n",
      "Macro F-Score: 0.8926522052774617\n",
      "Micro F-Score: 0.9054793367561653\n",
      "Average Accuracy: 0.8348529411764707\n",
      "\n",
      "\n",
      "k_fold validation: 7\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.1610294117647059\n",
      "Exact Prediction: 0.18705882352941178\n",
      "Macro F-Score: 0.8959562534485657\n",
      "Micro F-Score: 0.9074621820332968\n",
      "Average Accuracy: 0.838970588235294\n",
      "\n",
      "\n",
      "k_fold validation: 8\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16220588235294117\n",
      "Exact Prediction: 0.21529411764705883\n",
      "Macro F-Score: 0.8950018553918281\n",
      "Micro F-Score: 0.9069590889919865\n",
      "Average Accuracy: 0.8377941176470588\n",
      "\n",
      "\n",
      "k_fold validation: 9\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.1661764705882353\n",
      "Exact Prediction: 0.21764705882352942\n",
      "Macro F-Score: 0.8916409498774021\n",
      "Micro F-Score: 0.9042210544160028\n",
      "Average Accuracy: 0.8338235294117647\n",
      "\n",
      "\n",
      "k_fold validation: 10\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.1688235294117647\n",
      "Exact Prediction: 0.16117647058823528\n",
      "Macro F-Score: 0.8905211149276238\n",
      "Micro F-Score: 0.9032366824005396\n",
      "Average Accuracy: 0.8311764705882353\n",
      "\n",
      "\n",
      "Final Result: \n",
      "Average Hamming Loss: 0.16498111218635514\n",
      "Average Subset Accuracy: 0.1920944217875164\n",
      "Average Macro F-score: 0.8929775961478252\n",
      "Average Micro F-score: 0.9053568131466584\n",
      "Average of Average Accuracy: 0.835018887813645\n"
     ]
    }
   ],
   "source": [
    "col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "hamm_score = []\n",
    "subset_accu = []\n",
    "macro_f1 = []\n",
    "micro_f1 = []\n",
    "avg_accu = []\n",
    "cnt = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    x_train,x_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = np.array(Y.iloc[train_index].values.tolist()),np.array(Y.iloc[test_index].values.tolist())\n",
    "    print(\"k_fold validation: \" + str(cnt))\n",
    "    cnt+=1\n",
    "    \n",
    "    x_train = vectorizer.transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    print(x_train.shape,x_test.shape)\n",
    "    print(y_train.shape,y_test.shape)\n",
    "    \n",
    "    y_pred_val = []\n",
    "    for i in range(8):\n",
    "        print(i)\n",
    "        classifier = RandomForestClassifier()\n",
    "        tmp_y_train = y_train[:,i]\n",
    "        classifier.fit(x_train,tmp_y_train)\n",
    "        y_pred = classifier.predict(x_test)\n",
    "        y_pred_val.append(y_pred)\n",
    "    \n",
    "    y_test_val = np.array(y_test)\n",
    "    \n",
    "    score_list = y_test_val.T.tolist()\n",
    "    predict_score_list = y_pred_val\n",
    "    \n",
    "    ret = evaluation(score_list,predict_score_list)\n",
    "    hamm_score.append(ret[0])\n",
    "    subset_accu.append(ret[1])\n",
    "    macro_f1.append(ret[2])\n",
    "    micro_f1.append(ret[3])\n",
    "    avg_accu.append(ret[4])\n",
    "    print('\\n')\n",
    "print('Final Result: ')\n",
    "print('Average Hamming Loss: '+str(sum(hamm_score)/len(hamm_score)))\n",
    "print('Average Subset Accuracy: '+str(sum(subset_accu)/len(subset_accu)))\n",
    "print('Average Macro F-score: '+str(sum(macro_f1)/len(macro_f1)))\n",
    "print('Average Micro F-score: '+str(sum(micro_f1)/len(micro_f1)))\n",
    "print('Average of Average Accuracy: '+str(sum(avg_accu)/len(avg_accu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i+1for i in range(10)]\n",
    "labels.append('average')\n",
    "hamm_score.append(sum(hamm_score)/len(hamm_score))\n",
    "subset_accu.append(sum(subset_accu)/len(subset_accu))\n",
    "macro_f1.append(sum(macro_f1)/len(macro_f1))\n",
    "micro_f1.append(sum(micro_f1)/len(micro_f1))\n",
    "avg_accu.append(sum(avg_accu)/len(avg_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-fold</th>\n",
       "      <th>Hamming loss</th>\n",
       "      <th>Subset accuracy</th>\n",
       "      <th>Macro F-score</th>\n",
       "      <th>Micro F-score</th>\n",
       "      <th>Average Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.160546</td>\n",
       "      <td>0.197415</td>\n",
       "      <td>0.894289</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.839454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.168971</td>\n",
       "      <td>0.184706</td>\n",
       "      <td>0.892039</td>\n",
       "      <td>0.903258</td>\n",
       "      <td>0.831029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.167794</td>\n",
       "      <td>0.182353</td>\n",
       "      <td>0.891690</td>\n",
       "      <td>0.903510</td>\n",
       "      <td>0.832206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.165588</td>\n",
       "      <td>0.196471</td>\n",
       "      <td>0.891863</td>\n",
       "      <td>0.904931</td>\n",
       "      <td>0.834412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.163529</td>\n",
       "      <td>0.192941</td>\n",
       "      <td>0.894122</td>\n",
       "      <td>0.906460</td>\n",
       "      <td>0.836471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.185882</td>\n",
       "      <td>0.892652</td>\n",
       "      <td>0.905479</td>\n",
       "      <td>0.834853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.161029</td>\n",
       "      <td>0.187059</td>\n",
       "      <td>0.895956</td>\n",
       "      <td>0.907462</td>\n",
       "      <td>0.838971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.162206</td>\n",
       "      <td>0.215294</td>\n",
       "      <td>0.895002</td>\n",
       "      <td>0.906959</td>\n",
       "      <td>0.837794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.166176</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.891641</td>\n",
       "      <td>0.904221</td>\n",
       "      <td>0.833824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.168824</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.890521</td>\n",
       "      <td>0.903237</td>\n",
       "      <td>0.831176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>0.192094</td>\n",
       "      <td>0.892978</td>\n",
       "      <td>0.905357</td>\n",
       "      <td>0.835019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k-fold  Hamming loss  Subset accuracy  Macro F-score  Micro F-score  \\\n",
       "0         1      0.160546         0.197415       0.894289       0.908051   \n",
       "1         2      0.168971         0.184706       0.892039       0.903258   \n",
       "2         3      0.167794         0.182353       0.891690       0.903510   \n",
       "3         4      0.165588         0.196471       0.891863       0.904931   \n",
       "4         5      0.163529         0.192941       0.894122       0.906460   \n",
       "5         6      0.165147         0.185882       0.892652       0.905479   \n",
       "6         7      0.161029         0.187059       0.895956       0.907462   \n",
       "7         8      0.162206         0.215294       0.895002       0.906959   \n",
       "8         9      0.166176         0.217647       0.891641       0.904221   \n",
       "9        10      0.168824         0.161176       0.890521       0.903237   \n",
       "10  average      0.164981         0.192094       0.892978       0.905357   \n",
       "\n",
       "    Average Accuracy  \n",
       "0           0.839454  \n",
       "1           0.831029  \n",
       "2           0.832206  \n",
       "3           0.834412  \n",
       "4           0.836471  \n",
       "5           0.834853  \n",
       "6           0.838971  \n",
       "7           0.837794  \n",
       "8           0.833824  \n",
       "9           0.831176  \n",
       "10          0.835019  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rfc = pd.DataFrame(list(zip(labels,hamm_score,subset_accu,macro_f1,micro_f1,avg_accu)),\n",
    "              columns = ['k-fold','Hamming loss','Subset accuracy','Macro F-score','Micro F-score','Average Accuracy'])\n",
    "df_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold validation: 1\n",
      "(7650, 17402) (851, 17402)\n",
      "(7650, 8) (851, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.15716803760282022\n",
      "Exact Prediction: 0.19506462984723855\n",
      "Macro F-Score: 0.8951333978893801\n",
      "Micro F-Score: 0.9095672751859365\n",
      "Average Accuracy: 0.8428319623971798\n",
      "\n",
      "\n",
      "k_fold validation: 2\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16647058823529412\n",
      "Exact Prediction: 0.19411764705882353\n",
      "Macro F-Score: 0.8924726896315498\n",
      "Micro F-Score: 0.9044886938913264\n",
      "Average Accuracy: 0.8335294117647059\n",
      "\n",
      "\n",
      "k_fold validation: 3\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.1675\n",
      "Exact Prediction: 0.18235294117647058\n",
      "Macro F-Score: 0.8908023015800226\n",
      "Micro F-Score: 0.903253206489425\n",
      "Average Accuracy: 0.8325\n",
      "\n",
      "\n",
      "k_fold validation: 4\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16176470588235295\n",
      "Exact Prediction: 0.2011764705882353\n",
      "Macro F-Score: 0.893066983516237\n",
      "Micro F-Score: 0.9067322367305408\n",
      "Average Accuracy: 0.8382352941176469\n",
      "\n",
      "\n",
      "k_fold validation: 5\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.165\n",
      "Exact Prediction: 0.1776470588235294\n",
      "Macro F-Score: 0.8915011441561221\n",
      "Micro F-Score: 0.9051884400878825\n",
      "Average Accuracy: 0.8350000000000001\n",
      "\n",
      "\n",
      "k_fold validation: 6\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16014705882352942\n",
      "Exact Prediction: 0.21411764705882352\n",
      "Macro F-Score: 0.8954680621910044\n",
      "Micro F-Score: 0.908031416265518\n",
      "Average Accuracy: 0.8398529411764706\n",
      "\n",
      "\n",
      "k_fold validation: 7\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16073529411764706\n",
      "Exact Prediction: 0.18823529411764706\n",
      "Macro F-Score: 0.8946953316843127\n",
      "Micro F-Score: 0.9072077425927498\n",
      "Average Accuracy: 0.8392647058823529\n",
      "\n",
      "\n",
      "k_fold validation: 8\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.15970588235294117\n",
      "Exact Prediction: 0.2164705882352941\n",
      "Macro F-Score: 0.8959299029824703\n",
      "Micro F-Score: 0.9081684424150178\n",
      "Average Accuracy: 0.8402941176470589\n",
      "\n",
      "\n",
      "k_fold validation: 9\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16397058823529412\n",
      "Exact Prediction: 0.21764705882352942\n",
      "Macro F-Score: 0.8920119431011683\n",
      "Micro F-Score: 0.9053400118855591\n",
      "Average Accuracy: 0.836029411764706\n",
      "\n",
      "\n",
      "k_fold validation: 10\n",
      "(7651, 17402) (850, 17402)\n",
      "(7651, 8) (850, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Hamming Loss: 0.16661764705882354\n",
      "Exact Prediction: 0.18352941176470589\n",
      "Macro F-Score: 0.8911046337676853\n",
      "Micro F-Score: 0.9042993496072302\n",
      "Average Accuracy: 0.8333823529411765\n",
      "\n",
      "\n",
      "Final Result: \n",
      "Average Hamming Loss: 0.16290798023087025\n",
      "Average Subset Accuracy: 0.19703587474942977\n",
      "Average Macro F-score: 0.8932186390499954\n",
      "Average Micro F-score: 0.9062276815151187\n",
      "Average of Average Accuracy: 0.8370920197691298\n"
     ]
    }
   ],
   "source": [
    "col_names = ['Joy','Sadness','Anger','Disgust','Admiration','Surprise','Interest','Fear']\n",
    "hamm_score = []\n",
    "subset_accu = []\n",
    "macro_f1 = []\n",
    "micro_f1 = []\n",
    "avg_accu = []\n",
    "cnt = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    x_train,x_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = np.array(Y.iloc[train_index].values.tolist()),np.array(Y.iloc[test_index].values.tolist())\n",
    "    print(\"k_fold validation: \" + str(cnt))\n",
    "    cnt+=1\n",
    "    \n",
    "    x_train = vectorizer.transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    print(x_train.shape,x_test.shape)\n",
    "    print(y_train.shape,y_test.shape)\n",
    "    \n",
    "    y_pred_val = []\n",
    "    for i in range(8):\n",
    "        print(i)\n",
    "        classifier = SVC()\n",
    "        tmp_y_train = y_train[:,i]\n",
    "        classifier.fit(x_train,tmp_y_train)\n",
    "        y_pred = classifier.predict(x_test)\n",
    "        y_pred_val.append(y_pred)\n",
    "    \n",
    "    y_test_val = np.array(y_test)\n",
    "    \n",
    "    score_list = y_test_val.T.tolist()\n",
    "    predict_score_list = y_pred_val\n",
    "    \n",
    "    ret = evaluation(score_list,predict_score_list)\n",
    "    hamm_score.append(ret[0])\n",
    "    subset_accu.append(ret[1])\n",
    "    macro_f1.append(ret[2])\n",
    "    micro_f1.append(ret[3])\n",
    "    avg_accu.append(ret[4])\n",
    "    print('\\n')\n",
    "print('Final Result: ')\n",
    "print('Average Hamming Loss: '+str(sum(hamm_score)/len(hamm_score)))\n",
    "print('Average Subset Accuracy: '+str(sum(subset_accu)/len(subset_accu)))\n",
    "print('Average Macro F-score: '+str(sum(macro_f1)/len(macro_f1)))\n",
    "print('Average Micro F-score: '+str(sum(micro_f1)/len(micro_f1)))\n",
    "print('Average of Average Accuracy: '+str(sum(avg_accu)/len(avg_accu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i+1for i in range(10)]\n",
    "labels.append('average')\n",
    "hamm_score.append(sum(hamm_score)/len(hamm_score))\n",
    "subset_accu.append(sum(subset_accu)/len(subset_accu))\n",
    "macro_f1.append(sum(macro_f1)/len(macro_f1))\n",
    "micro_f1.append(sum(micro_f1)/len(micro_f1))\n",
    "avg_accu.append(sum(avg_accu)/len(avg_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-fold</th>\n",
       "      <th>Hamming loss</th>\n",
       "      <th>Subset accuracy</th>\n",
       "      <th>Macro F-score</th>\n",
       "      <th>Micro F-score</th>\n",
       "      <th>Average Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.157168</td>\n",
       "      <td>0.195065</td>\n",
       "      <td>0.895133</td>\n",
       "      <td>0.909567</td>\n",
       "      <td>0.842832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.166471</td>\n",
       "      <td>0.194118</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.904489</td>\n",
       "      <td>0.833529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>0.182353</td>\n",
       "      <td>0.890802</td>\n",
       "      <td>0.903253</td>\n",
       "      <td>0.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.201176</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>0.906732</td>\n",
       "      <td>0.838235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.891501</td>\n",
       "      <td>0.905188</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.160147</td>\n",
       "      <td>0.214118</td>\n",
       "      <td>0.895468</td>\n",
       "      <td>0.908031</td>\n",
       "      <td>0.839853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.160735</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.894695</td>\n",
       "      <td>0.907208</td>\n",
       "      <td>0.839265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.216471</td>\n",
       "      <td>0.895930</td>\n",
       "      <td>0.908168</td>\n",
       "      <td>0.840294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.163971</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.892012</td>\n",
       "      <td>0.905340</td>\n",
       "      <td>0.836029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.166618</td>\n",
       "      <td>0.183529</td>\n",
       "      <td>0.891105</td>\n",
       "      <td>0.904299</td>\n",
       "      <td>0.833382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average</td>\n",
       "      <td>0.162908</td>\n",
       "      <td>0.197036</td>\n",
       "      <td>0.893219</td>\n",
       "      <td>0.906228</td>\n",
       "      <td>0.837092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k-fold  Hamming loss  Subset accuracy  Macro F-score  Micro F-score  \\\n",
       "0         1      0.157168         0.195065       0.895133       0.909567   \n",
       "1         2      0.166471         0.194118       0.892473       0.904489   \n",
       "2         3      0.167500         0.182353       0.890802       0.903253   \n",
       "3         4      0.161765         0.201176       0.893067       0.906732   \n",
       "4         5      0.165000         0.177647       0.891501       0.905188   \n",
       "5         6      0.160147         0.214118       0.895468       0.908031   \n",
       "6         7      0.160735         0.188235       0.894695       0.907208   \n",
       "7         8      0.159706         0.216471       0.895930       0.908168   \n",
       "8         9      0.163971         0.217647       0.892012       0.905340   \n",
       "9        10      0.166618         0.183529       0.891105       0.904299   \n",
       "10  average      0.162908         0.197036       0.893219       0.906228   \n",
       "\n",
       "    Average Accuracy  \n",
       "0           0.842832  \n",
       "1           0.833529  \n",
       "2           0.832500  \n",
       "3           0.838235  \n",
       "4           0.835000  \n",
       "5           0.839853  \n",
       "6           0.839265  \n",
       "7           0.840294  \n",
       "8           0.836029  \n",
       "9           0.833382  \n",
       "10          0.837092  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svc = pd.DataFrame(list(zip(labels,hamm_score,subset_accu,macro_f1,micro_f1,avg_accu)),\n",
    "              columns = ['k-fold','Hamming loss','Subset accuracy','Macro F-score','Micro F-score','Average Accuracy'])\n",
    "df_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
